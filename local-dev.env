
# CoFound.ai Local Development Environment
# This file contains settings for running CoFound.ai locally with Docker

# Basic Configuration
LLM_PROVIDER=test
DEVELOPMENT_MODE=true
DEBUG=true
LOG_LEVEL=INFO

# Database Configuration
DATABASE_URL=postgresql://cofoundai_user:cofoundai_password@postgres:5432/cofoundai
DATABASE_HOST=postgres
DATABASE_PORT=5432
DATABASE_NAME=cofoundai
DATABASE_USER=cofoundai_user
DATABASE_PASSWORD=cofoundai_password

# Redis Configuration
REDIS_URL=redis://redis:6379/0

# API Configuration
API_HOST=0.0.0.0
API_PORT=5000
CORS_ORIGINS=*

# Frontend Configuration
FRONTEND_URL=http://localhost:3000

# Vector Database (Chroma)
CHROMA_HOST=chroma
CHROMA_PORT=8000

# Local LLM Options (for future use)
LOCAL_LLM_ENABLED=false
LOCAL_LLM_MODEL_PATH=/app/models
OLLAMA_HOST=http://localhost:11434

# Feature Flags for Local Development
ENABLE_MONITORING=true
ENABLE_ANALYTICS=false
ENABLE_EXTENSIBLE_ARCHITECTURE=true
ENABLE_MICROSERVICES=false
ENABLE_CLOUD_DEPLOYMENT=false

# Mock/Test Settings
MOCK_LLM_RESPONSES=true
ENABLE_DEMO_DATA=true
