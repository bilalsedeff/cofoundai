modules = ["python-3.12", "nodejs-20", "web"]
run = "uvicorn cofoundai.api.backend_api:app --host 0.0.0.0 --port 3000"

[nix]
channel = "stable-24_05"

[deployment]
run = ["sh", "-c", "uvicorn undefined:app --host 0.0.0.0 --port 3000"]

[workflows]
runButton = "Run Backend"

[[workflows.workflow]]
name = "Run Backend"
author = 43415462
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python start_backend.py"

[[workflows.workflow]]
name = "Monitor System"
author = 43415462
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python services/monitoring/monitor_dashboard.py"

[[workflows.workflow]]
name = "Test LangGraph"
author = 43415462
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python test_langgraph.py"

[[workflows.workflow]]
name = "Test Dream Flow"
author = 43415462
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python test_dream_flow.py"

[[workflows.workflow]]
name = "Run API Server"
author = 43415462
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python cofoundai/api/backend_api.py"

[[workflows.workflow]]
name = "Test Free LLMs"
author = 43415462
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python test_free_llms.py"

[[workflows.workflow]]
name = "Test Dream Flow (Fixed)"
author = 43415462
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python test_dream_flow.py"

[[ports]]
localPort = 5000
externalPort = 80

[[ports]]
localPort = 5001
